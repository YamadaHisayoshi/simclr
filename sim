import os
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Subset
import numpy as np

seed = 42
np.random.seed(seed)
torch.manual_seed(seed)

# 画像の変換を定義
transform = transforms.Compose([
    transforms.ToTensor(),  # テンソルに変換
    # 必要に応じて他の変換を追加
])

# ルートディレクトリを指定
root_dir = '/path/to/root'  # ここを実際のパスに置き換えてください

# ImageFolderデータセットを作成
dataset = datasets.ImageFolder(root=root_dir, transform=transform)
dataloader = DataLoader(subset, batch_size=32, shuffle=True)
# 各フォルダから10枚ずつのインデックスを取得
subset_indices = []
for class_idx in range(len(dataset.classes)):
    class_indices = np.where(np.array(dataset.targets) == class_idx)[0]
    chosen_indices = np.random.choice(class_indices, 10, replace=False)
    subset_indices.extend(chosen_indices)

# Subsetを作成
subset = Subset(dataset, subset_indices)

project_directory/
│
├── config/
│   ├── config.yaml    # メインの設定ファイル
│   └── model/         # モデル関連の設定ファイル
│       └── simclr.yaml
├── simclr_module.py   # SimCLRのモデルクラス
└── train.py           # トレーニングスクリプト

config/config.yaml
defaults:
  - model: simclr

model:
  _target_: simclr_module.SimCLR
  lr: 0.001
  temperature: 0.5

trainer:
  max_epochs: 100
  gpus: 1

data:
  batch_size: 128
  dataset_path: "/path/to/dataset"

config/model/simsiam.yaml
backbone:
  type: resnet50
  pretrained: false
projection_head:
  input_dim: 2048
  hidden_dim: 2048
  output_dim: 128

simclr_module.py

import torch
import torch.nn as nn
import torchvision
import pytorch_lightning as pl
from omegaconf import OmegaConf

class SimCLR(pl.LightningModule):
    def __init__(self, backbone, projection_head, lr, temperature):
        super().__init__()
        resnet = getattr(torchvision.models, backbone['type'])(pretrained=backbone['pretrained'])
        self.backbone = nn.Sequential(*list(resnet.children())[:-1])
        self.projection_head = nn.Sequential(
            nn.Linear(projection_head['input_dim'], projection_head['hidden_dim']),
            nn.ReLU(),
            nn.Linear(projection_head['hidden_dim'], projection_head['output_dim'])
        )
        self.criterion = nn.CrossEntropyLoss()
        self.lr = lr
        self.temperature = temperature

    def forward(self, x):
        h = self.backbone(x).flatten(start_dim=1)
        z = self.projection_head(h)
        return z

    def training_step(self, batch, batch_idx):
        (x0, x1), _ = batch
        z0 = self.forward(x0)
        z1 = self.forward(x1)
        logits = self.compute_logits(z0, z1)
        labels = torch.arange(len(x0)).cuda()  # Positive pairs across the batch
        loss = self.criterion(logits / self.temperature, labels)
        return loss

    def configure_optimizers(self):
        optim = torch.optim.Adam(self.parameters(), lr=self.lr)
        return optim

    def compute_logits(self, z0, z1):
        z0_norm = nn.functional.normalize(z0, dim=1)
        z1_norm = nn.functional.normalize(z1, dim=1)
        return torch.matmul(z0_norm, z1_norm.T)
import hydra
from omegaconf import DictConfig, OmegaConf
import pytorch_lightning as pl
from pytorch_lightning import Trainer
from simclr_module import SimCLR
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

@hydra.main(config_path="config", config_name="config")
def train_model(cfg: DictConfig):
    print(OmegaConf.to_yaml(cfg))
    
    transform = transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    train_dataset = datasets.ImageFolder(root=cfg.data.dataset_path, transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=cfg.data.batch_size, shuffle=True)

    model = SimCLR(
        backbone=cfg.model.backbone,
        projection_head=cfg.model.projection_head,
        lr=cfg.model.lr,
        temperature=cfg.model.temperature
    )
    
    trainer = Trainer(max_epochs=cfg.trainer.max_epochs, gpus=cfg.trainer.gpus)
    trainer.fit(model, train_loader)

if __name__ == "__main__":
    train_model()

Lightly SimCLRチュートリアルをHydraで使う例

LightlyのSimCLRチュートリアルをHydraで使える形式に書き直してみましょう。

1. データセットの定義

Hydraでは、データセットのパスや設定をyamlファイルで定義するのが一般的です。

# dataset.yaml
data:
  root: /path/to/your/dataset
  batch_size: 256
  num_workers: 8
content_copy
Use code with caution.
Yaml

2. SimCLRモデルと学習設定の定義

SimCLRモデルの構造や学習に関する設定もyamlファイルで定義します。

# simclr.yaml
model:
  backbone: resnet18  # 使用するバックボーンネットワーク
  hidden_dim: 2048     # projection headの隠れ層の次元
  out_dim: 128        # 最終的な埋め込みベクトルの次元

optimizer:
  name: Adam          # optimizerの種類
  lr: 1e-3             # 学習率

training:
  epochs: 100         # 学習エポック数
  device: cuda         # 学習に使用するデバイス
content_copy
Use code with caution.
Yaml

3. Hydraを使った学習スクリプト

Hydraを使ってデータセットとモデルの設定を読み込み、学習を実行するスクリプトの例です。

import hydra
from omegaconf import DictConfig

import lightly
from lightly.models.modules.simclr_projection_head import SimCLRProjectionHead
from lightly.loss import NTXentLoss

from torch import nn
from torch.utils.data import DataLoader

# データ拡張の設定
collate_fn = lightly.data.SimCLRCollateFunction(
    input_size=32,
    gaussian_blur=0.5,
)

# 学習データのtransform
train_transform = lightly.data.SimCLRTransform(
    input_size=32,
    gaussian_blur=0.5,
)

@hydra.main(config_path=".", config_name="config")
def main(cfg: DictConfig):
    # データセットの読み込み
    dataset = lightly.data.LightlyDataset(root=cfg.data.root, transform=train_transform)
    dataloader = DataLoader(
        dataset,
        batch_size=cfg.data.batch_size,
        num_workers=cfg.data.num_workers,
        collate_fn=collate_fn,
    )

    # モデルの定義
    resnet = lightly.models.ResNetGenerator('resnet-18', 1, num_splits=0)
    backbone = nn.Sequential(*list(resnet.children())[:-1])
    projection_head = SimCLRProjectionHead(cfg.model.hidden_dim, cfg.model.hidden_dim, cfg.model.out_dim)
    model = nn.Sequential(backbone, projection_head)

    # optimizer, loss, deviceの設定
    optimizer = getattr(torch.optim, cfg.optimizer.name)(model.parameters(), lr=cfg.optimizer.lr)
    criterion = NTXentLoss()
    device = torch.device(cfg.training.device)

    # モデルをデバイスに移動
    model.to(device)

    # 学習ループ
    for epoch in range(cfg.training.epochs):
        for (x0, x1), _, _ in dataloader:
            x0 = x0.to(device)
            x1 = x1.to(device)

            # forward pass
            z0 = model(x0)
            z1 = model(x1)

            # lossの計算
            loss = criterion(z0, z1)

            # backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        print(f"Epoch: {epoch}, Loss: {loss.item():.4f}")


if __name__ == "__main__":
    main()
content_copy
Use code with caution.
Python

4. config.yamlの作成

最後に、上記のyamlファイルを全て読み込むためのconfig.yamlを作成します。

# config.yaml
defaults:
  - dataset: dataset.yaml
  - simclr: simclr.yaml
content_copy
Use code with caution.
Yaml

実行

以上の設定ファイルとスクリプトを用意したら、コマンドラインからHydraを実行して学習を開始できます。

python train.py
content_copy
Use code with caution.
Bash

解説

データセットやモデルの設定をyamlファイルに切り出すことで、コードの可読性が向上し、設定の変更が容易になります。

Hydraを使うことで、yamlファイルの管理やコマンドライン引数からの設定の上書きが簡単に行えます。

上記の例では、LightlyのSimCLRチュートリアルの基本的な部分をHydraで使える形式に書き直しています。

実際の利用シーンに合わせて、データセットのパスやモデルの構造、学習設定などを変更してください。
